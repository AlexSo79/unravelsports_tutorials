{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸŒ€ Quick Start Guide: It's all starting to unravel!\n",
    "\n",
    "First run `pip install unravelsports` if you haven't already!\n",
    "\n",
    "\n",
    "-----\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install unravelsports --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Processing Data\n",
    "\n",
    "1. Load [Kloppy](https://github.com/PySport/kloppy) dataset. See [in-depth Tutorial](1_kloppy_gnn_train.ipynb) on how do processes multiple match files.\n",
    "2. Convert to Graph format using `GraphConverter`\n",
    "3. Create dataset for easy processing with [Spektral](https://graphneural.network/) using `CustomSpektralDataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing frames: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 500/500 [00:00<00:00, 561.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 477 graphs into CustomSpektralDataset...\n",
      "Loading 477 graphs into CustomSpektralDataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from unravel.soccer import GraphConverter\n",
    "from unravel.utils import CustomSpektralDataset\n",
    "\n",
    "from kloppy import skillcorner\n",
    "\n",
    "from unravel.utils import dummy_labels\n",
    "\n",
    "# Load Kloppy dataset\n",
    "kloppy_dataset = skillcorner.load_open_data(\n",
    "    match_id=4039,\n",
    "    include_empty_frames=False,\n",
    "    limit=500,  # limit to 500 frames in this example\n",
    ")\n",
    "\n",
    "# Initialize the Graph Converter, with dataset, labels and settings\n",
    "converter = GraphConverter(dataset=kloppy_dataset, labels=dummy_labels(kloppy_dataset))\n",
    "\n",
    "# Compute the graphs and add them to the CustomSpektralDataset\n",
    "dataset = CustomSpektralDataset(graph=converter.to_spektral_graphs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Split Data\n",
    "\n",
    "Split the dataset with the built in `split_test_train_validation` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spektral.data import DisjointLoader\n",
    "\n",
    "train, test, val = dataset.split_test_train_validation(\n",
    "    split_train=4, split_test=1, split_validation=1, random_seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Compile Model\n",
    "\n",
    "1. Initialize the `CrystalGraphClassifier`.\n",
    "2. Compile the model with a loss function, optimizer and your preferred metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "from unravel.classifiers import CrystalGraphClassifier\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, BinaryAccuracy\n",
    "\n",
    "model = CrystalGraphClassifier()\n",
    "\n",
    "model.compile(\n",
    "    loss=BinaryCrossentropy(), optimizer=Adam(), metrics=[AUC(), BinaryAccuracy()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Fit Model\n",
    "\n",
    "1. Create a [`DisjointLoader`](https://graphneural.network/loaders/#disjointloader) for training and validation sets.\n",
    "2. Fit the model. Note: set `use_multiprocessing=True` to speed up training significantly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jbekkers/PycharmProjects/unravelsports/.venv311/lib/python3.11/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer GlorotUniform is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 2s 26ms/step - loss: 16.1988 - auc: 0.4597 - binary_accuracy: 0.4560 - val_loss: 7.9675 - val_auc: 0.5101 - val_binary_accuracy: 0.4625\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - ETA: 0s - loss: 8.1257 - auc: 0.5055 - binary_accuracy: 0.5283 WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 3 batches). You may need to use the repeat() function when building your dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 0s 9ms/step - loss: 8.1257 - auc: 0.5055 - binary_accuracy: 0.5283\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 3.8924 - auc: 0.5408 - binary_accuracy: 0.5535\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 0s 10ms/step - loss: 3.6436 - auc: 0.4814 - binary_accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 0s 11ms/step - loss: 2.2543 - auc: 0.4966 - binary_accuracy: 0.4969\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.7266 - auc: 0.4905 - binary_accuracy: 0.4780\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.4315 - auc: 0.5282 - binary_accuracy: 0.5126\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 1.1989 - auc: 0.5094 - binary_accuracy: 0.4748\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 0.9823 - auc: 0.5714 - binary_accuracy: 0.5440\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 1.0795 - auc: 0.5228 - binary_accuracy: 0.5031\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1779b2410>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "\n",
    "loader_tr = DisjointLoader(train, batch_size=batch_size)\n",
    "loader_va = DisjointLoader(val, epochs=1, shuffle=False, batch_size=batch_size)\n",
    "\n",
    "model.fit(\n",
    "    loader_tr.load(),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=loader_tr.steps_per_epoch,\n",
    "    use_multiprocessing=True,\n",
    "    validation_data=loader_va.load(),\n",
    "    callbacks=[EarlyStopping(monitor=\"loss\", patience=5, restore_best_weights=True)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Evaluate Model Performance\n",
    "\n",
    "1. Create another `DisjointLoader`, this time for the test set.\n",
    "2. Evaluate model performance on the test set. This evaluation function uses the `metrics` passed to `model.compile`\n",
    "\n",
    "Note: Our performance is really bad because we're using random labels, very few epochs and a small dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.7569 - auc: 0.4881 - binary_accuracy: 0.4684\n"
     ]
    }
   ],
   "source": [
    "loader_te = DisjointLoader(test, epochs=1, shuffle=False, batch_size=batch_size)\n",
    "results = model.evaluate(loader_te.load())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predict\n",
    "\n",
    "1. Use unseen data to predict on. In this example we're using the test dataset.\n",
    "2. We have to re-create `loader_te` because `DisjointLoader` is a generator.\n",
    "3. Setting `batch_size` and `use_multiprocessing=True` on prediction helps speed up the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.32064953],\n",
       "       [0.5187207 ],\n",
       "       [0.36767447],\n",
       "       [0.58158153],\n",
       "       [0.648303  ],\n",
       "       [0.7250808 ],\n",
       "       [0.45932224],\n",
       "       [0.17837673],\n",
       "       [0.40539873],\n",
       "       [0.4424542 ],\n",
       "       [0.30549103],\n",
       "       [0.4686426 ],\n",
       "       [0.45274827],\n",
       "       [0.48409605],\n",
       "       [0.52468264],\n",
       "       [0.48941866],\n",
       "       [0.45071444],\n",
       "       [0.40024903],\n",
       "       [0.43896046],\n",
       "       [0.4752483 ],\n",
       "       [0.6113058 ],\n",
       "       [0.51407444],\n",
       "       [0.63001126],\n",
       "       [0.4740725 ],\n",
       "       [0.6078143 ],\n",
       "       [0.42406863],\n",
       "       [0.42664722],\n",
       "       [0.5456678 ],\n",
       "       [0.6497228 ],\n",
       "       [0.10468224],\n",
       "       [0.28870958],\n",
       "       [0.35573283],\n",
       "       [0.50675493],\n",
       "       [0.26084217],\n",
       "       [0.5045665 ],\n",
       "       [0.4551955 ],\n",
       "       [0.2941906 ],\n",
       "       [0.17870983],\n",
       "       [0.645881  ],\n",
       "       [0.44119328],\n",
       "       [0.5141012 ],\n",
       "       [0.4944313 ],\n",
       "       [0.5526908 ],\n",
       "       [0.3726117 ],\n",
       "       [0.01953349],\n",
       "       [0.43424365],\n",
       "       [0.6119593 ],\n",
       "       [0.17366503],\n",
       "       [0.32349864],\n",
       "       [0.23837146],\n",
       "       [0.36960262],\n",
       "       [0.40078542],\n",
       "       [0.60070145],\n",
       "       [0.38831863],\n",
       "       [0.4297107 ],\n",
       "       [0.30132666],\n",
       "       [0.19354764],\n",
       "       [0.33943865],\n",
       "       [0.6698272 ],\n",
       "       [0.493429  ],\n",
       "       [0.71516454],\n",
       "       [0.47075588],\n",
       "       [0.9052064 ],\n",
       "       [0.48426422],\n",
       "       [0.51765573],\n",
       "       [0.621886  ],\n",
       "       [0.56246924],\n",
       "       [0.5652972 ],\n",
       "       [0.46242762],\n",
       "       [0.57170457],\n",
       "       [0.18469568],\n",
       "       [0.42506087],\n",
       "       [0.69418275],\n",
       "       [0.37345868],\n",
       "       [0.50700355],\n",
       "       [0.4964876 ],\n",
       "       [0.32357928],\n",
       "       [0.692147  ],\n",
       "       [0.5441656 ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader_te = DisjointLoader(test, batch_size=batch_size, epochs=1, shuffle=False)\n",
    "loaded_pred = model.predict(loader_te.load(), use_multiprocessing=True)\n",
    "\n",
    "loaded_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
